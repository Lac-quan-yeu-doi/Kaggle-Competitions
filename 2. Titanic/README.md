# ğŸ“ˆ Logistic Regression Using NumPy

This project implements **Logistic Regression** from scratch using only **NumPy**. It demonstrates how to fit a logistic model to data using the **Adam optimizer**.

## ğŸ“– Overview
- **Implementation time:** 11/03/2025 - 18/03/2025  
- **Competition link:** [Here](https://www.kaggle.com/competitions/titanic) (Please refer to this link for information about dataset)

## â­ Features

- Implements **Logistic Regression** without using machine learning libraries.  
- Supports **Adam** for optimization.  
- Generates a submission file for the competition.

## ğŸ”§ Installation

### Requirements

Ensure you have Python and the necessary libraries installed:

```bash
pip install -r requirements.txt
```

## ğŸš€ Usage

1. Open the Jupyter Notebook (`.ipynb` file).
2. Run each cell sequentially to:
   - Load and preprocess data.  
   - Implement and test **Logistic Regression** with **Adam optimizer**.

## ğŸ› ï¸ Implementation Details

- **Logistic Function (Sigmoid):** Converts linear outputs into probabilities.  
- **Adam Optimizer:** Iteratively updates model parameters to minimize loss.  
- **Loss Function:** Binary Cross-Entropy (Log Loss) is used to evaluate model performance.  
- **Decision Boundary:** Thresholding at 0.5 to classify outputs.

## ğŸ“Š Results

Recorded: 18/03/2025  
![Model Performance](Result_ranking.png)

## ğŸ‘¤ Author

Vo Nguyen Phat

## ğŸ“œ License

This project is open-source and available under the MIT License.

